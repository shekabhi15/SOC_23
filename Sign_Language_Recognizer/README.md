<h1>Sign Language Recognition</h1>


This project focuses on recognizing sign language gestures using computer vision techniques. It consists of three main files: create_data, convert_csv, and model. Each file performs a specific task in the sign language recognition pipeline.

<h3>Files</h3>
1. create_gesture_data.py
The create_data.py file is responsible for capturing images from a webcam and storing them in separate directories based on different labels. The collected images will serve as the training dataset for the sign language recognition model. This file performs the following tasks:

Utilizes the webcam to capture frames.
Allows the user to assign labels to different sign language gestures.
Saves the captured images in separate directories based on their assigned labels.
2.convert_csv.py</br>The convert_csv.py file converts the collected images into CSV format, representing the pixel values of each image. This step is necessary to preprocess the data and make it suitable for training a Convolutional Neural Network (CNN). The convert_csv.py file performs the following tasks:

Reads the images from the previously created directories.
Converts each image into a grayscale representation.
Flattens the image into a single-dimensional array of pixel values.
Stores the pixel values of all images along with their respective labels in a CSV file.

3. model.py</br>The model.py file contains a Convolutional Neural Network (CNN) model that is trained using the CSV data generated by the convert_csv.py file. The CNN model is designed to learn and recognize patterns in the sign language gestures. This file performs the following tasks:

Loads the CSV data containing the pixel values of the sign language gesture images.
Divides the data into training and testing sets.
Constructs a CNN model architecture using libraries like TensorFlow or PyTorch.
Trains the model on the training dataset.
Evaluates the model's performance on the testing dataset.
Saves the trained model for future use.
<h3>Usage</h3>
To use this project, follow these steps:

Run the create_data.py file to capture and store sign language gesture images in separate directories for different labels.

Once the data is collected, run the convert_csv.py file to convert the images into CSV format, representing the pixel values of each image.

After the CSV data is generated, run the model.py file to train the CNN model on the converted data. This will create and save a trained model that can be used for sign language recognition.

To recognize sign language gestures in real-time, you can use the trained model along with computer vision techniques to process the input frames from a webcam or any other image source.

<h3>Dependencies</h3>
The following dependencies are required to run the project:

Python (3.x)
OpenCV
NumPy
Pandas
TensorFlow or PyTorch (depending on the chosen library for the CNN model)
