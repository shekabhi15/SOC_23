
<h1>Sign Language Recognition Project</h1>
    <h2>Introduction</h2>
    <p>
        This project aims to build a Sign Language Recognition (SLR) system using Long Short-Term Memory (LSTM) model. The system utilizes the MediaPipe and OpenCV libraries to generate a dataset using the webcam for training the LSTM model.
    </p>
    
<h2>Features</h2>
    <ul>
        <li>Real-time Sign Language Recognition using webcam</li>
        <li>LSTM model for handling sequential data and long-term dependencies</li>
        <li>MediaPipe for detecting hand gestures and landmarks</li>
        <li>OpenCV for processing webcam input and generating dataset</li>
    </ul>

<h2>Requirements</h2>
    <ul>
        <li>Python 3.9</li>
        <li>TensorFlow</li>
        <li>Keras</li>
        <li>MediaPipe</li>
        <li>OpenCV</li>
    </ul>


<h2>Usage</h2>
    <p>
        Before running the training script, ensure the dataset is generated by using the script in the notebook. The training data will be saved in a specific format to be used by the LSTM model.


<h2>Acknowledgments</h2>
    <p>
        Special thanks to the developers of TensorFlow, Keras, MediaPipe, and OpenCV for their incredible contributions to the deep learning and computer vision communities.
    </p>

